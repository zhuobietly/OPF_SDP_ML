using PowerModels
using InfrastructureModels
using Mosek
using MosekTools
using CSV
using DataFrames
using Random
using JSON
using Dates
using Printf

# å¯é€‰ï¼šæŸ¥çœ‹å†…å­˜ï¼ˆä¸»æµç¨‹ä¸è°ƒç”¨ï¼‰
function print_memory_usage()
    println("ğŸ§   Mem usage: ", round(Sys.total_memory() / 1024^3, digits=2), " GB total | ",
            round(Sys.free_memory() / 1024^3, digits=2), " GB free")
end

# è§£ææ–‡ä»¶åï¼šcase14_0.30_perturbation_301_2.json
# è¿”å› (k, seed, id)
function parse_k_seed_id_from_filename(fname::String)
    m = match(r"^[A-Za-z0-9]+_([0-9]+(?:\.[0-9]+)?)_perturbation_([0-9]+)_([0-9]+)\.json$", fname)
    if m === nothing
        return (NaN, missing, missing)
    end
    k     = try parse(Float64, m.captures[1]) catch; NaN; end
    seed  = try parse(Int,     m.captures[2]) catch; missing; end   # 301ï¼ˆä¸ç”¨ï¼‰
    idno  = try parse(Int,     m.captures[3]) catch; missing; end   # 2ï¼ˆè¦ç”¨ï¼‰
    return (k, seed, idno)
end

_fmt_k(k::Float64) = isnan(k) ? nothing : @sprintf("%.2f", k)

"""
æ„å»º chordal-SDP çš„ OPF å¹¶ç”¨ MOSEK æ±‚è§£ã€‚
ï¼ˆä¸è®¡ç®—/ä¿å­˜åŸå§‹é‚»æ¥ï¼Œä¸è°ƒç”¨ GCï¼‰
"""
function solve(data, model, clique_merging)
    pm = InfrastructureModels.InitializeInfrastructureModel(
        model, data, PowerModels._pm_global_keys, PowerModels.pm_it_sym
    )
    PowerModels.ref_add_core!(pm.ref)

    nw = collect(InfrastructureModels.nw_ids(pm, pm_it_sym))[1]
    println("Beginning chordal extension (merge = $(clique_merging))")

    cadj_chordal, lookup_index, sigma =
        PowerModels._chordal_extension(pm, nw; clique_merge=clique_merging)

    cliques = PowerModels._maximal_cliques(cadj_chordal)
    lookup_bus_index = Dict((reverse(p) for p in pairs(lookup_index)))
    groups = [[lookup_bus_index[gi] for gi in g] for g in cliques]

    pm.ext[:SDconstraintDecomposition] =
        PowerModels._SDconstraintDecomposition(groups, lookup_index, sigma)

    println("Building the OPF")
    PowerModels.build_opf(pm)

    result = optimize_model!(pm, optimizer=Mosek.Optimizer)
    return result
end

# ================= ä¸»è„šæœ¬ =================
current_dir = @__DIR__
println("Current directory: ", current_dir)

# åŸºç¡€æ¡ˆä¾‹ä¸è¾“å…¥ç›®å½•
case_file  = "case118.m"
case_name  = replace(case_file, ".m" => "")
input_dir  = joinpath(current_dir, "output", "PL_118_10")

# é…ç½®
formulations = [Chordal_AMD, Chordal_MFI, Chordal_MD]
merging_opts = [true, false]

# ç»“æœè¡¨åˆ—åï¼ˆä¸ä½ æ ·ä¾‹ä¸€è‡´ï¼‰
function empty_results_df()
    return DataFrame(
        Formulation     = String[],
        perturbation    = String[],
        Case            = String[],
        Merge           = Bool[],
        A_parameter     = Float64[],
        SolveTime       = Float64[],
        Status          = String[],
        objective       = Float64[],
        SolutionStatus  = String[],
        ID              = Int[],
        load_id         = String[],
    )
end

run_id_global = 0  # å…¨å±€é€’å¢ IDï¼ˆä¿ç•™ï¼‰

for json_file in readdir(input_dir)
    endswith(json_file, ".json") || continue

    filepath = joinpath(input_dir, json_file)
    println("\nReading scenario: ", filepath)
    loads = JSON.parsefile(filepath)

    # æ¯ä¸ªåœºæ™¯å•ç‹¬å‡†å¤‡ data
    data_path = joinpath(current_dir, "data", case_file)
    data      = PowerModels.parse_file(data_path)
    for (id, load) in loads["load"]
        data["load"][id]["pd"] = load["pd"]
        data["load"][id]["qd"] = load["qd"]
    end

    # ä»æ–‡ä»¶åè§£æï¼šk/seed/idï¼ˆä»…ä½¿ç”¨ idï¼‰
    k_detect, seed_detect, id_detect = parse_k_seed_id_from_filename(json_file)
    k_token  = _fmt_k(k_detect)                 # "0.30" æˆ– nothing
    A_param  = isnan(k_detect) ? NaN : k_detect # A_parameter åˆ—
    load_id  = (id_detect === missing) ? "" : string(id_detect)  # ä»…ç”¨ idï¼ˆ=2ï¼‰

    # åˆ— perturbationï¼šä¿ç•™æ–‡ä»¶åå»åç¼€
    perturbation_name = replace(json_file, ".json" => "")

    # æ¯åœºæ™¯ä¸€ä¸ª CSVï¼šä»…ç”¨ id å‘½åï¼Œä¸å¸¦ seed
    # pglib_opf_<case>_k_<k>_perturbation_<id>.csv
    name_tokens = ["pglib_opf", case_name]
    if k_token !== nothing
        append!(name_tokens, ["k", k_token])
    end
    append!(name_tokens, ["perturbation", (load_id == "" ? perturbation_name : load_id) * ".csv"])
    results_csv = joinpath(current_dir, join(name_tokens, "_"))
    println("Scene CSV -> ", results_csv)

    # å†™è¡¨å¤´
    CSV.write(results_csv, empty_results_df())

    # 3 Ã— 2 = 6 æ¬¡æ±‚è§£
    for fm in formulations
        for merging in merging_opts
            run_id_global += 1
            try
                println("Solving with formulation: ", fm, " | merging: ", merging)
                result = solve(data, fm, merging)

                solve_time  = get(result, "solve_time", NaN)
                term_status = string(get(result, "termination_status", ""))
                obj_val     = get(result, "objective", NaN)
                sol_status  = string(get(result, "solution_status", ""))  # å¯èƒ½ä¸å­˜åœ¨

                row = DataFrame(
                    Formulation     = [string(fm)],
                    perturbation    = [perturbation_name],
                    Case            = [case_name],
                    Merge           = [merging],
                    A_parameter     = [A_param],
                    SolveTime       = [solve_time],
                    Status          = [term_status],
                    objective       = [obj_val],
                    SolutionStatus  = [sol_status],
                    ID              = [run_id_global],
                    load_id         = [load_id],   # åªç”¨ idï¼ˆ=2ï¼‰
                )
                CSV.write(results_csv, row, append=true)

            catch e
                @warn "Error solving with formulation=$(fm), merging=$(merging)" e
                row_err = DataFrame(
                    Formulation     = [string(fm)],
                    perturbation    = [perturbation_name],
                    Case            = [case_name],
                    Merge           = [merging],
                    A_parameter     = [A_param],
                    SolveTime       = [NaN],
                    Status          = ["error"],
                    objective       = [NaN],
                    SolutionStatus  = [""],
                    ID              = [run_id_global],
                    load_id         = [load_id],
                )
                CSV.write(results_csv, row_err, append=true)
            end
        end
    end
end

println("\nâœ… å®Œæˆã€‚æ¯ä¸ªåœºæ™¯å·²å„è‡ªç”Ÿæˆ 1 ä¸ª CSVï¼ˆå‘½ååªç”¨ idï¼‰ã€‚")
