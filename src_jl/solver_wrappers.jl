module SolverWrappers
using PowerModels
using InfrastructureModels
using Mosek
using MosekTools
using DataFrames
using CSV
using Ipopt
using JuMP
using NPZ
using SparseArrays
include("../src_jl/chordalvisual.jl")
using .ChordalVisualizer: visualize_fillin, edge_lists, visualize_fillin3, edge_lists3

include("../src_jl/ChordalStatsLite.jl")
using .ChordalStatsLite: compute_stats_from_vars,
                        cliques_from_peo,
                        stats_dataframe,
                        append_stats_csv
include("../src_jl/LightGC.jl")
using .LightGC: cleanup!, safe_close
include("../src_jl/network_perturbation.jl")
using .ChordalPerturb
export solve
# ç”¨ Pipe æ•è· stdout/stderrï¼ˆè·¨ Julia ç‰ˆæœ¬ç¨³ï¼‰
# ---------------- æ•è· stdout/stderrï¼šç®¡é“ä¼˜å…ˆï¼Œç¼ºå¤±åˆ™ç”¨ä¸´æ—¶æ–‡ä»¶ ----------------
const _HAS_PIPE = isdefined(Base, :pipe)

# --- æ•è· stdout/stderr åˆ°å­—ç¬¦ä¸²ï¼ˆç”¨ä¸´æ—¶æ–‡ä»¶ï¼Œè·¨ç‰ˆæœ¬ç¨³ï¼‰ ---
function _run_with_capture(f::Function)
    outpath = tempname(); errpath = tempname()
    ret = open(outpath, "w") do outio
        open(errpath, "w") do errio
            redirect_stdout(outio) do
                redirect_stderr(errio) do
                    f()
                end
            end
        end
    end
    out_s = isfile(outpath) ? read(outpath, String) : ""
    err_s = isfile(errpath) ? read(errpath, String) : ""
    try rm(outpath; force=true); rm(errpath; force=true) catch; end
    return ret, string(out_s, "\n", err_s)
end

# --- è§£æ Mosek æ—¥å¿—ï¼šIterations / Primal / Dual / Relative gap ---
# è§£æ Mosek æ—¥å¿—ï¼šä¼˜å…ˆè¯»æ˜¾å¼ Summaryï¼›å¦åˆ™è¯» ITE è¡¨æ ¼æœ€åä¸€è¡Œ
# è¿”å› (iters::Union{Int,Missing}, pfeas::Union{Float64,Missing},
#        dfeas::Union{Float64,Missing}, relgap::Union{Float64,Missing}, time_sec::Union{Float64,Missing})
function parse_mosek_log_all(logtxt::AbstractString)
    # ---- 1) æ˜¾å¼ Summary è¡Œï¼ˆPrimal/Dual infeasibility, Relative gap, Iterations, Timeï¼‰----
    iters = try
        m = match(r"Iterations:\s+(\d+)", logtxt); m === nothing ? missing : parse(Int, m.captures[1])
    catch; missing; end
    pfeas = try
        m = match(r"Primal\s+(?:in)?feasibility\s*[:=]\s*([0-9.eE+\-]+)", logtxt)
        m === nothing ? missing : parse(Float64, m.captures[1])
    catch; missing; end
    dfeas = try
        m = match(r"Dual\s+(?:in)?feasibility\s*[:=]\s*([0-9.eE+\-]+)", logtxt)
        m === nothing ? missing : parse(Float64, m.captures[1])
    catch; missing; end
    relgap = try
        m = match(r"Relative\s+gap\s*[:=]\s*([0-9.eE+\-]+)", logtxt)
        m === nothing ? missing : parse(Float64, m.captures[1])
    catch; missing; end
    time_sec = try
        m = match(r"Optimizer terminated\. Time:\s*([0-9.]+)", logtxt)
        m === nothing ? missing : parse(Float64, m.captures[1])
    catch; missing; end

    # ---- 2) è‹¥æ²¡æ‰¾åˆ° Summaryï¼Œå°±ä» ITE è¡¨æ ¼æœ€åä¸€è¡Œå–å€¼ ----
    if any(ismissing, (iters, pfeas, dfeas, relgap))
        last = nothing
        for ln in eachline(IOBuffer(logtxt))
            # å½¢å¦‚ï¼š "16  9.0e-09  3.9e-09  2.8e-13  1.00e+00   6.097266787e+00   6.097266781e+00   9.7e-10  0.01"
            m = match(r"^\s*(\d+)\s+([0-9.eE+\-]+)\s+([0-9.eE+\-]+)\s+[0-9.eE+\-]+\s+\S+\s+([0-9.eE+\-]+)\s+([0-9.eE+\-]+)\s+[0-9.eE+\-]+\s+([0-9.]+)\s*$", ln)
            if m !== nothing
                last = m
            end
        end
        if last !== nothing
            iters = ismissing(iters) ? parse(Int, last.captures[1]) : iters
            pfeas = ismissing(pfeas) ? parse(Float64, last.captures[2]) : pfeas
            dfeas = ismissing(dfeas) ? parse(Float64, last.captures[3]) : dfeas
            # ç›¸å¯¹é—´éš™=|POBJ-DOBJ|/max(1,|POBJ|)
            if ismissing(relgap)
                pobj = parse(Float64, last.captures[4])
                dobj = parse(Float64, last.captures[5])
                relgap = abs(pobj - dobj) / max(1.0, abs(pobj))
            end
            time_sec = ismissing(time_sec) ? parse(Float64, last.captures[6]) : time_sec
        end
    end
    return iters, pfeas, dfeas, relgap, time_sec
end

# ----------------------- å°å·¥å…·ï¼šå¥å£®å–æ•° -----------------------
# å…¼å®¹ String/Symbol é”®
_get_any(dict, k, default=missing) = haskey(dict, k) ? dict[k] : default
_get_any(dict, ks::Vector, default=missing) = begin
    for k in ks
        if haskey(dict, k); return dict[k]; end
    end
    return default
end

# ä»å­—å…¸è¯»å–æ•°å€¼ï¼ˆNumberï¼‰ï¼Œå¦åˆ™è¿”å› missing
function _getnum(d, keysets...; default=missing)
    for ks in keysets
        v = _get_any(d, ks, nothing)
        if v isa Number; return Float64(v); end
    end
    return default
end

# åµŒå¥—è¯»å–ï¼ˆå¦‚ result["solution"]ï¼‰
function _get_nested(d, path::Vector{Any}, default=missing)
    cur = d
    for k in path
        if !(cur isa AbstractDict) || !haskey(cur, k); return default; end
        cur = cur[k]
    end
    return cur
end

# KKT æ¡ä»¶çš„â€œå°ºåº¦ä»£ç†â€ï¼šç”¨ç½‘ç»œæ•°æ®é‡Œå¯æ‹¿åˆ°çš„ç³»æ•°/ç‰©ç†é‡æ„é€  max/min æ¯”
function _coeff_ratio_from_data(data; tol=1e-16)
    coeffs = Float64[]
    # buses
    bus = get(data, "bus", get(data, :bus, Dict()))
    for (_k, b) in bus
        for key in ("pd","qd","gs","bs","gsh","bsh")
            v = get(b, key, get(b, Symbol(key), nothing))
            v isa Number && push!(coeffs, abs(float(v)))
        end
    end
    # branches
    brs = get(data, "branch", get(data, :branch, Dict()))
    for (_k, br) in brs
        for key in ("r","x","b","g","br_b","br_r","br_x")
            v = get(br, key, get(br, Symbol(key), nothing))
            v isa Number && push!(coeffs, abs(float(v)))
        end
        # çº¿è·¯é¢å®šä¹Ÿåæ˜ é‡çº§
        for key in ("rate_a","rate_b","rate_c")
            v = get(br, key, get(br, Symbol(key), nothing))
            v isa Number && push!(coeffs, abs(float(v)))
        end
    end
    # ç”Ÿæˆæœºä¸Šä¸‹ç•Œï¼ˆé‡çº²ï¼‰
    gens = get(data, "gen", get(data, :gen, Dict()))
    for (_k, g) in gens
        for key in ("pmax","pmin","qmax","qmin")
            v = get(g, key, get(g, Symbol(key), nothing))
            v isa Number && push!(coeffs, abs(float(v)))
        end
    end
    coeffs = filter(!iszero, coeffs)
    return isempty(coeffs) ? missing :
           (maximum(coeffs) / max(minimum(coeffs), tol))
end

# è´´è¾¹è®¡æ•°ï¼ˆç”µå‹ã€å‘ç”µæœº P/Qã€çº¿è·¯æµï¼‰â€”â€”å°½åŠ›è€Œä¸ºï¼Œæ‹¿ä¸åˆ°å°± missing
function _count_active_limits(result, data; tol=1e-4)
    sol = _get_any(result, ["solution", :solution], nothing)
    sol isa AbstractDict || return missing
    cnt = 0

    # bus voltage
    sbus = _get_any(sol, ["bus", :bus], Dict())
    dbus = get(data, "bus", get(data, :bus, Dict()))
    for (id, bv) in sbus
        vm = _get_any(bv, ["vm", :vm], nothing)
        vm isa Number || continue
        bd = get(dbus, string(id), get(dbus, id, nothing))
        bd isa AbstractDict || continue
        vmin = _get_any(bd, ["vmin", :vmin], nothing)
        vmax = _get_any(bd, ["vmax", :vmax], nothing)
        (vmin isa Number && abs(vm - vmin) <= tol) && (cnt += 1)
        (vmax isa Number && abs(vm - vmax) <= tol) && (cnt += 1)
    end

    # generators P/Q
    sgen = _get_any(sol, ["gen", :gen], Dict())
    dgen = get(data, "gen", get(data, :gen, Dict()))
    for (id, gv) in sgen
        gd = get(dgen, string(id), get(dgen, id, nothing))
        gd isa AbstractDict || continue
        pg = _get_any(gv, ["pg", :pg], nothing)
        qg = _get_any(gv, ["qg", :qg], nothing)
        if pg isa Number
            pmin = _get_any(gd, ["pmin", :pmin], nothing)
            pmax = _get_any(gd, ["pmax", :pmax], nothing)
            (pmin isa Number && abs(pg - pmin) <= tol) && (cnt += 1)
            (pmax isa Number && abs(pg - pmax) <= tol) && (cnt += 1)
        end
        if qg isa Number
            qmin = _get_any(gd, ["qmin", :qmin], nothing)
            qmax = _get_any(gd, ["qmax", :qmax], nothing)
            (qmin isa Number && abs(qg - qmin) <= tol) && (cnt += 1)
            (qmax isa Number && abs(qg - qmax) <= tol) && (cnt += 1)
        end
    end

    # branch flow (active power) vs rate_a
    sbr = _get_any(sol, ["branch", :branch], Dict())
    dbr = get(data, "branch", get(data, :branch, Dict()))
    for (id, bv) in sbr
        pf = _get_any(bv, ["pf", :pf], nothing)
        bd = get(dbr, string(id), get(dbr, id, nothing))
        ratea = (bd isa AbstractDict) ? _get_any(bd, ["rate_a", :rate_a], nothing) : nothing
        if pf isa Number && ratea isa Number
            abs(abs(pf) - ratea) <= tol && (cnt += 1)
        end
    end

    return cnt
end

function solve(data, model, clique_merging, case_name; alpha = 3.0, id_name = nothing, tokens = nothing, perturbation = nothing, id_detect = -1, file_name = "default")
    #case_name = "$(case_name)_$(formulation)_$(clique_merging)",è¯·å¸®æˆ‘æŠŠcase_nameå’Œå…¶ä»–ä¸œè¥¿åˆ†å¼€
    original_case_name = case_name
    # ä»åŸå§‹åç§°ä¸­æ‹†åˆ†


    # --- ä»…ç”¨äºç”Ÿæˆæ‰°åŠ¨å€™é€‰ï¼šä¸´æ—¶ pmï¼ˆä¸å»ºæ¨¡ï¼‰ ---
    pm0 = InfrastructureModels.InitializeInfrastructureModel(model, data, PowerModels._pm_global_keys, PowerModels.pm_it_sym)
    PowerModels.ref_add_core!(pm0.ref)
    nw0 = collect(InfrastructureModels.nw_ids(pm0, pm_it_sym))[1]
    #åœ¨è¿™ä¹‹å‰æ·»åŠ ç½‘ç»œæ‰°åŠ¨
    # === åœ¨è¿™é‡Œç”Ÿæˆ 1+6+3 ä¸ªå€™é€‰å›¾ï¼ˆä¸åšåˆ†è§£ä¸åˆå¹¶ï¼Œè¿™ä¸€æ­¥åªè´Ÿè´£â€œæ‰°åŠ¨â€ä¸å…ƒä¿¡æ¯ï¼‰ ===
    perturbs = ChordalPerturb.generate_perturbations(pm0, nw0)
    # ä¹‹åä½ å¯ä»¥é€‰æ‹©ä¸€ä¸ªï¼ˆæˆ–å¾ªç¯å¤šä¸ªï¼‰æ¥åšåˆ†è§£ï¼š
    # ä¸¾ä¾‹ï¼šå…ˆå¯¹åŸå§‹ç½‘ç»œç»§ç»­ï¼š
    A0 = perturbs[1].adj
    for pg in perturbs
        # 1) ä¸ºè¯¥æ‰°åŠ¨æ–°å»º pm
        pm = InfrastructureModels.InitializeInfrastructureModel(model, data, PowerModels._pm_global_keys, PowerModels.pm_it_sym)
        PowerModels.ref_add_core!(pm.ref)
        nw = collect(InfrastructureModels.nw_ids(pm, pm_it_sym))[1]
        # 2) åœ¨è¯¥æ‰°åŠ¨å›¾ä¸Šåš chordal extension / clique æå–
        adj_use, lookup_index = pg.adj, pg.lookup_index
        adj, cadj, lookup_index, sigma, q =
            PowerModels._chordal_extension(pm, adj_use, lookup_index, clique_merging, alpha)
        @assert q == invperm(sigma) "ç½®æ¢ä¸ä¸€è‡´ï¼šåº”æ»¡è¶³ q == invperm(sigma)"

        cliques = PowerModels._maximal_cliques(cadj)
        lookup_bus_index = Dict(reverse(p) for p in pairs(lookup_index))
        groups = [[lookup_bus_index[gi] for gi in g] for g in cliques]

        # 3) **åœ¨å»ºæ¨¡å‰**æŠŠåˆ†è§£å†™å…¥ pm.extï¼ˆå…³é”®ï¼ï¼‰
        pm.ext[:SDconstraintDecomposition] =
            PowerModels._SDconstraintDecomposition(groups, lookup_index, sigma)

        # ---------- ä¸‰è‰²å¯è§†åŒ–ï¼šåŸåº ----------
        network_type = "$(pg.kind)_$(pg.idx)"
        save_name = "$(network_type)_$(model)_$(clique_merging)_$(alpha)_$(id_detect)"
        save_path = joinpath("result", "figure", "graph", "$(case_name)", "$(save_name)_fillin.png")
        visualize_fillin3(A0, adj, cadj; q=q, savepath=save_path)
        println("âœ… ç»˜åˆ¶å®ŒæˆåŸå§‹é¡ºåºï¼‰ï¼š", save_path)
       
        # ---------- ä¸‰è‰²å¯è§†åŒ–ï¼šPEO é¡ºåº ----------
        save_path_peo = joinpath("result", "figure", "graph", "$(case_name)", "$(save_name)_fillin_peo.png")
        ChordalVisualizer.visualize_fillin3(A0, adj, cadj; q=sigma, savepath=save_path_peo)
        println("âœ… ç»˜åˆ¶å®Œæˆï¼ˆPEO é¡ºåºï¼‰ï¼š", save_path_peo)

        #â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”save the chordal graph matrixâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        # file_name = 

        # scene_id
        if file_name != "default"
            scene_id = "$(network_type)_$(alpha)_$(string(model))"
            save_path_csv = joinpath("data", "chordal_graph_matrix", "$(case_name)", "$(file_name)", "$(scene_id)_chordal_edges.csv")
            mkpath(dirname(save_path_csv))
    
            # è·å–è¾¹åˆ—è¡¨å¹¶è½¬ä¸º DataFrame
            I, J, V = findnz(cadj)
            df_edges = DataFrame(
                i = I .- 1,  # è½¬ä¸º 0-based ç´¢å¼•
                j = J .- 1,  # è½¬ä¸º 0-based ç´¢å¼•  
                w = V
            )
    
            # ä¿å­˜ä¸º CSVï¼ˆæ— è¡¨å¤´ï¼ŒåŒ¹é…ä½ çš„ Python è¯»å–ä»£ç ï¼‰
            CSV.write(save_path_csv, df_edges; header=false)

        end
        cliques = PowerModels._maximal_cliques(cadj)
        lookup_bus_index = Dict((reverse(p) for p = pairs(lookup_index)))
        groups = [[lookup_bus_index[gi] for gi in g] for g in cliques]
        pm.ext[:SDconstraintDecomposition] = PowerModels._SDconstraintDecomposition(groups, lookup_index, sigma)
        # ========= ç»“æ„ç»Ÿè®¡ï¼ˆæ±‚è§£å‰å·²å®Œæˆï¼‰=========
        stats = compute_stats_from_vars(; cadj=cadj, sigma=sigma, cliques=cliques, cadj0=adj)
        #result = optimize_model!(pm, optimizer=Mosek.Optimizer)
        # ===== æ±‚è§£ =====
        PowerModels.build_opf(pm)
        # ç”¨ optimizer_with_attributes ç¡®ä¿ Mosek è¾“å‡ºæ—¥å¿—ï¼ˆä¸è¦ä¾èµ– set_optimizer_attributeï¼‰
        opt = optimizer_with_attributes(
            Mosek.Optimizer,
            "MSK_IPAR_LOG" => 1,
            "MSK_IPAR_LOG_INTPNT" => 1,
            "QUIET" => 0,          # JuMP å±‚é™éŸ³å¼€å…³
        )

        # è¿è¡Œå¹¶æ•è·æ—¥å¿—
        println("ğŸ”· å¼€å§‹æ±‚è§£ï¼š$(case_name) / $(network_type) / $(model) / $(clique_merging) / Î±=$(alpha) / id=$(id_detect) / perturb=$(pg.kind)_$(pg.idx)" )
        result, mosek_log = _run_with_capture() do
            optimize_model!(pm, optimizer=opt)
        end

        # -- MOI è¯»å–è¿­ä»£æ­¥ï¼ˆä¼˜å…ˆç”¨ MOIï¼›æ‹¿ä¸åˆ°å†ç”¨æ—¥å¿—ï¼‰ ï¼ˆ// NEWï¼‰
        log_iters, log_pr, log_dr, log_rg, log_time = parse_mosek_log_all(mosek_log)

        iterations = log_iters
        primal_res = log_pr
        dual_res   = log_dr
        rel_gap    = log_rg
        mosektime  = log_time

        # ï¼ˆå¯é€‰ï¼‰æŠŠæ—¥å¿—å†™æ–‡ä»¶ï¼Œæ–¹ä¾¿ä½ ç¡®è®¤åˆ°åº•æ•åˆ°äº†ä»€ä¹ˆ
        

        
        # â€”â€” å…¼å®¹ Symbol / String é”® â€”â€” 
        _get(r, ks, default=missing) = begin
            for k in ks
                if haskey(r, k); return r[k]; end
            end
            return default
        end

        solve_time  = _get(result, ["solve_time", :solve_time], NaN)
        term_status = string(_get(result, ["termination_status", :termination_status, "status", :status], ""))
        obj_val     = _get(result, ["objective", :objective, "obj_val", :obj_val], NaN)
        sol_status  = string(_get(result, ["solution_status", :solution_status, "primal_status", :primal_status], ""))
        ##
        # è‹¥æ²¡ç›´æ¥ç»™ç›¸å¯¹é—´éš™ï¼Œå°è¯•ç”¨ä¸Šä¸‹ç•Œ/å¯¹å¶ç›®æ ‡ä¼°è®¡
        if rel_gap === missing
            obj_lb = _getnum(result, ["objective_lb", :objective_lb, "best_bound", :best_bound,
                                    "dual_objective", :dual_objective])
            if !(obj_val === missing || obj_lb === missing)
                denom = max(1.0, abs(obj_val))
                rel_gap = abs(obj_val - obj_lb) / denom
            end
        end
        # KKT æ¡ä»¶ proxyï¼ˆåŸºäºæ•°æ®çš„é‡çº²èŒƒå›´ï¼‰
        kkt_cond_proxy = _coeff_ratio_from_data(data)

        # è´´è¾¹æ•°é‡ç»Ÿè®¡ï¼ˆæœ‰è§£ä¸”æ•°æ®é½å…¨æ‰ä¼šè¿”å› Intï¼Œå¦åˆ™ missingï¼‰
        active_limits = _count_active_limits(result, data; tol=1e-4)


        # â€”â€” ä½ è¦çš„â€œæ±‚è§£ç»“æœâ€åˆ—ï¼ˆæ”¾å‰é¢ï¼‰â€”â€”
        df_core = DataFrame(
            network_type    = [network_type], # ä¾‹ï¼šoriginal_0, light_1, heavy_2
            Formulation     = [string(model)],
            Perturbation    = [perturbation],     # ä¾‹ï¼š(Ïƒ, seed)
            Case            = [case_name],
            Merge           = [clique_merging],
            A_parameter     = [alpha],
            SolveTime       = [solve_time],
            mosektime       = [mosektime],
            Status          = [term_status],
            objective       = [obj_val],
            SolutionStatus  = [sol_status],
            ID              = [id_detect],
            load_id         = [id_name],
            # æ–°å¢æ•°å€¼/æ”¶æ•›åˆ—
            Iterations      = [iterations],
            PrimalRes       = [primal_res],
            DualRes         = [dual_res],
            RelGap          = [rel_gap],
            KKTCondProxy    = [kkt_cond_proxy],
            ActiveLimits    = [active_limits],
        )

        # â€”â€” ç»“æ„ç»Ÿè®¡ï¼ˆç´§è·Ÿåœ¨åé¢ï¼‰â€”â€”
        df_stats = DataFrame(
            r_max        = [stats.r_max],
            t            = [stats.t],
            r_var        = [stats.r_var],
            sum_r_sq     = [stats.sum_r_sq],
            sum_r_cu     = [stats.sum_r_cu],
            sep_max      = [stats.sep_max],
            sep_mean     = [stats.sep_mean],
            sum_sep_sq   = [stats.sum_sep_sq],
            tree_max_deg = [stats.tree_max_degree],
            tree_h       = [stats.tree_height],
            fillin       = [stats.fillin_ratio],
            coupling     = [stats.coupling_proxy],
        )

        # â€”â€” åˆå¹¶æˆä¸€è¡Œ â€”â€” 
        df = hcat(df_core, df_stats)

        # â€”â€” ç”Ÿæˆ CSV è·¯å¾„ï¼ˆä¿®æ­£é€»è¾‘ï¼‰â€”â€”
        stats_csv_path = joinpath("data", "clique_stats", case_name, join(tokens, "_"))
        println("âœ… ç”Ÿæˆ CSV è·¯å¾„ï¼š", stats_csv_path)
        mkpath(dirname(stats_csv_path))

        # â€”â€” è¿½åŠ å†™å…¥ â€”â€” 
        if isfile(stats_csv_path)
            CSV.write(stats_csv_path, df; append=true)
        else
            CSV.write(stats_csv_path, df)
        end
    end # for pg in perturbs
    return nothing
end
end # module