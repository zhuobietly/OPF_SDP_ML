import os, sys, yaml, torch
from pathlib import Path
PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))
import torch
import matplotlib.pyplot as plt
import numpy as np
from registries import register
from registries import build  
import evaluation.evaluators 
from gcn_utils.model_logger import ModelLogger

@register("task", "opf_basic_task")
class OPFBasicTask:
    def __init__(self, model, loss_fn, device="cpu", lr=1e-3, log_dir=None):
        self.model = model.to(device)
        self.loss_fn = loss_fn
        self.device = device
        self.opt = torch.optim.Adam(model.parameters(), lr=lr)
        
        # æ·»åŠ æŸå¤±è®°å½•åˆ—è¡¨
        self.train_losses = []
        self.val_losses = []
        self.log_dir = log_dir
        
        if log_dir:
            self.logger = ModelLogger(self.model, self.opt, log_dir=log_dir)
            self.logger.record_model()
        else:
            self.logger = None

    def _to_device(self, batch):
        for k, v in batch.items():
            if torch.is_tensor(v): batch[k] = v.to(self.device)
            elif isinstance(v, dict):
                for kk, vv in v.items():
                    if torch.is_tensor(vv): v[kk] = vv.to(self.device)
        return batch

    def train_one_epoch(self, loader):
        self.model.train()
        total = 0.0
        for step, batch in enumerate(loader):
            batch = self._to_device(batch)
            self.opt.zero_grad()
            out = self.model(batch)
            loss = self.loss_fn(out, batch)
            loss.backward()
            
            if self.logger:
                self.logger.pre_step()
            
            self.opt.step()
            
            if self.logger:
                self.logger.log_gradients(step)
                
            total += loss.item()
        
        avg_loss = total / max(1, len(loader))
        self.train_losses.append(avg_loss)  # è®°å½•è®­ç»ƒæŸå¤±
        return avg_loss

    @torch.no_grad()
    def validate(self, loader):  # éªŒè¯æŸå¤±
        self.model.eval()
        total_loss = 0.0
        for batch in loader:
            batch = self._to_device(batch)
            out = self.model(batch)
            loss = self.loss_fn(out, batch)  # ä½¿ç”¨ç›¸åŒçš„æŸå¤±å‡½æ•°
            total_loss += loss.item()
        
        avg_loss = total_loss / max(1, len(loader))
        self.val_losses.append(avg_loss)  # è®°å½•éªŒè¯æŸå¤±
        return avg_loss

    def plot_loss_curves(self, cfg):
        save_path = cfg["evaluator"]["output_dir"]
        """ç»˜åˆ¶è®­ç»ƒå’ŒéªŒè¯æŸå¤±æ›²çº¿"""
        if not self.train_losses:
            print("No training losses to plot")
            return
            
        plt.figure(figsize=(10, 6))
        
        epochs = range(1, len(self.train_losses) + 1)
        
        # ç»˜åˆ¶è®­ç»ƒæŸå¤±
        plt.plot(epochs, self.train_losses, 'b-', label='Training Loss', linewidth=2)
        
        # ç»˜åˆ¶éªŒè¯æŸå¤±ï¼ˆå¦‚æœæœ‰ï¼‰
        if self.val_losses:
            val_epochs = range(1, len(self.val_losses) + 1)
            plt.plot(val_epochs, self.val_losses, 'r-', label='Validation Loss', linewidth=2)
        
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Training and Validation Loss')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡æ³¨ï¼ˆå¯é€‰ï¼Œåªåœ¨epochè¾ƒå°‘æ—¶æ˜¾ç¤ºï¼‰
        if len(self.train_losses) <= 20:
            for i, loss in enumerate(self.train_losses):
                plt.annotate(f'{loss:.3f}', (i+1, loss), textcoords="offset points", 
                           xytext=(0,10), ha='center', fontsize=8)
        
        plt.tight_layout()
        

        save_path = os.path.join(save_path, "loss_curves.png")

        
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
        print(f"Loss curves saved to: {save_path}")
        
        # æ‰“å°æŸå¤±ç»Ÿè®¡
        print(f"\nğŸ“Š Loss Statistics:")
        print(f"Final Training Loss: {self.train_losses[-1]:.6f}")
        if self.val_losses:
            print(f"Final Validation Loss: {self.val_losses[-1]:.6f}")
            print(f"Best Validation Loss: {min(self.val_losses):.6f} (Epoch {self.val_losses.index(min(self.val_losses))+1})")

    def save_loss_data(self, cfg):
        save_path = cfg["evaluator"]["output_dir"]
        save_path = os.path.join(save_path, "loss_data.csv")
        import csv
        with open(save_path, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['Epoch', 'Train_Loss', 'Val_Loss'])
            
            max_len = max(len(self.train_losses), len(self.val_losses))
            for i in range(max_len):
                train_loss = self.train_losses[i] if i < len(self.train_losses) else ''
                val_loss = self.val_losses[i] if i < len(self.val_losses) else ''
                writer.writerow([i+1, train_loss, val_loss])
        
        print(f"Loss data saved to: {save_path}")
    
    @torch.no_grad()
    def test_with_evaluator(self, loader, cfg):
        """
        cfg ç¤ºä¾‹ 1ï¼šä¸€ç»´æ ‡é‡å›å½’
        cfg = {"evaluator": {"name": "scalar_only"}, "output_dir": "./outputs"}

        cfg ç¤ºä¾‹ 2ï¼šæ•°ç»„å›å½’ + åˆ†ç±»
        cfg = {"evaluator": {"name": "arr_cls"}, "output_dir": "./outputs"}
        """
        name = cfg["evaluator"]["name"]
        output_dir = cfg["evaluator"]["output_dir"]
        evaluator = build("evaluator", name, output_dir=output_dir)
        return evaluator.run(self.model, loader, device=self.device, output_dir=output_dir)



